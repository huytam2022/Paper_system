import argparse
import time
import random
from blockchains.node import Node
from blockchains.Source_Chains import SourceChain
from consensus_layer import LightConsensus
import csv

def _random_partition_sizes(n, k):
    """
    Tr·∫£ v·ªÅ list ƒë·ªô d√†i k sao cho t·ªïng = n v√† m·ªói ph·∫ßn >= 1.
    V√≠ d·ª•: n=10, k=3 -> [3, 2, 5]
    """
    if k == 1:
        return [n]
    # ch·ªçn k-1 ƒëi·ªÉm c·∫Øt trong (1..n-1)
    cuts = sorted(random.sample(range(1, n), k - 1))
    sizes = [a - b for a, b in zip(cuts + [n], [0] + cuts)]
    return sizes


def simulate_partitioned_blockchain(num_nodes, num_partitions, tx_count_per_node, max_rounds):
    assert num_nodes >= num_partitions, "S·ªë node ph·∫£i l·ªõn h∆°n ho·∫∑c b·∫±ng s·ªë ph√¢n v√πng"

    # Kh·ªüi t·∫°o node
    nodes = [Node(f"node_{i}", SourceChain) for i in range(num_nodes)]
    print(f"‚úÖ T·ªïng s·ªë node: {len(nodes)}")

    # Chia ng·∫´u nhi√™n nodes cho c√°c ph√¢n v√πng
    random.shuffle(nodes)
    sizes = _random_partition_sizes(num_nodes, num_partitions)
    partitions = []
    offset = 0
    for sz in sizes:
        partitions.append(nodes[offset:offset + sz])
        offset += sz

    # In c·∫•u h√¨nh ph√¢n v√πng (ng·∫´u nhi√™n)
    for idx, partition in enumerate(partitions):
        print(f" - Ph√¢n v√πng {idx+1}: {len(partition)} node")

    # === CSV tracking (per-partition) ===
    rounds_per_partition = []
    accepted_blocks_per_partition = []
    dropped_txs_per_partition = []
    liveness_per_partition = []

    all_results = []
    total_dropped_txs = 0
    partition_liveness = []
    fork_resolution_time = random.uniform(0.5, 2.0)  # gi·∫£ l·∫≠p 0.5‚Äì2s

    for idx, partition in enumerate(partitions):
        print(f"\nüöÄ Kh·ªüi ch·∫°y ph√¢n v√πng {idx+1}...")

        # K·∫øt n·ªëi peer n·ªôi b·ªô ph√¢n v√πng (m·ªói node k·∫øt n·ªëi t·ªëi ƒëa 3 peer ng·∫´u nhi√™n trong v√πng)
        for local_idx, node in enumerate(partition):
            node.name = f"node_{idx}_{local_idx}"
            peers = [n for n in partition if n != node]
            if peers:
                for p in random.sample(peers, min(len(peers), 3)):
                    node.connect(p)

        # Sinh giao d·ªãch trong v√πng
        txs = []
        for node in partition:
            for j in range(tx_count_per_node):
                tx_id = f"tx_{node.name}_{j}"
                tx_str = node.chain.add_transaction({"msg": "data"}, "type", tx_id)
                txs.append(tx_str)

        # Ph√°t t√°n giao d·ªãch trong v√πng
        for node in partition:
            for peer in node.peers:
                for tx in txs:
                    peer.receive_tx(tx, node)

        # ƒê·ªìng thu·∫≠n n·ªôi b·ªô ph√¢n v√πng
        consensus = LightConsensus(partition, confirm_delay = random.uniform(0.6, 1.2), quorum_ratio=2/3)
        accepted_blocks = 0
        dropped_txs = 0

        # random s·ªë rounds cho ph√¢n v√πng n√†y (1..max_rounds)
        rounds = random.randint(1, max_rounds)
        print(f" ‚è±Ô∏è Ph√¢n v√πng {idx+1} s·∫Ω ch·∫°y {rounds} v√≤ng ƒë·ªìng thu·∫≠n.")

        for r in range(rounds):
            # 1) Ch·ªçn proposer an to√†n
            proposer = consensus.select_proposer()
            if proposer is None:
                # Kh√¥ng c√≥ proposer h·ª£p l·ªá trong v√≤ng n√†y -> b·ªè qua
                continue

            # 2) Th·ª≠ t·∫°o block
            blk = proposer.chain.generate_block()

            # 3) N·∫øu kh√¥ng c√≥ block (mempool r·ªóng / ch∆∞a ƒë·∫°t ng∆∞·ª°ng), b∆°m 1 dummy tx r·ªìi th·ª≠ l·∫°i
            if not blk:
                tx_id = f"dummy_p{idx}_r{r}_{time.time_ns()}"
                proposer.chain.add_transaction({"msg": "filler"}, "type", tx_id)
                blk = proposer.chain.generate_block()

            # 4) N·∫øu v·∫´n kh√¥ng c√≥ block -> b·ªè qua v√≤ng n√†y
            if not blk:
                continue

            # 5) G√°n metadata cho block
            blk["block_id"] = f"p{idx}_r{r}"
            blk["tx_count"] = len(blk.get("transactions", []))
            blk["is_valid"] = True
            blk["proposer"] = proposer

            # 6) X√°c su·∫•t fork/xung ƒë·ªôt nh·∫π
            if random.random() < random.uniform(0.15, 0.3):
                dropped_txs += random.randint(2, 6)
                continue

            # 7) X√°c nh·∫≠n block
            if consensus.confirm_block(blk):
                accepted_blocks += 1

        print(f"‚úÖ Ph√¢n v√πng {idx+1} ƒë√£ x√°c nh·∫≠n {accepted_blocks}/{rounds} kh·ªëi.")
        partition_liveness.append(accepted_blocks / rounds)
        total_dropped_txs += dropped_txs
        all_results.append((idx+1, accepted_blocks))

        # === Ghi l·∫°i ƒë·ªÉ xu·∫•t CSV ===
        rounds_per_partition.append(rounds)
        accepted_blocks_per_partition.append(accepted_blocks)
        dropped_txs_per_partition.append(dropped_txs)
        liveness_per_partition.append(accepted_blocks / rounds if rounds > 0 else 0.0)

    # H·ª£p nh·∫•t sau khi c√°c ph√¢n v√πng ƒë√£ ch·∫°y xong
    print("\nüîó B·∫Øt ƒë·∫ßu h·ª£p nh·∫•t c√°c ph√¢n v√πng...")
    time.sleep(fork_resolution_time)  # m√¥ ph·ªèng th·ªùi gian gi·∫£i quy·∫øt fork

    for partition_id, block_count in all_results:
        print(f" - Ph√¢n v√πng {partition_id}: {block_count} kh·ªëi ƒë√£ ƒë∆∞·ª£c x√°c nh·∫≠n.")

    print("\nüìä T·ªïng h·ª£p sau h·ª£p nh·∫•t:")
    print(f"‚è±Ô∏è Th·ªùi gian gi·∫£i quy·∫øt fork: {fork_resolution_time:.2f} gi√¢y")
    print(f"‚ùå T·ªïng s·ªë giao d·ªãch b·ªã lo·∫°i trong fork ho·∫∑c xung ƒë·ªôt: {total_dropped_txs}")
    print(f"‚úÖ T√≠nh s·ªëng trung b√¨nh c·ªßa ph√¢n v√πng: {sum(partition_liveness)/len(partition_liveness)*100:.1f}%")

    # ƒê·ªìng thu·∫≠n to√†n c·ª•c sau h·ª£p nh·∫•t
    print("\nüïí ƒêo th·ªùi gian ƒë·ªìng thu·∫≠n to√†n m·∫°ng sau h·ª£p nh·∫•t...")
    
    global_consensus = LightConsensus(nodes, confirm_delay = random.uniform(0.6, 1.2), quorum_ratio=2/3)
    global_proposer = global_consensus.select_proposer()

    # T·∫°o 1 giao d·ªãch gi·∫£ ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ block
    tx_id = f"global_tx_{time.time_ns()}"
    _ = global_proposer.chain.add_transaction({"msg": "global merge"}, "type", tx_id)

    start_time = time.perf_counter()
    global_block = global_proposer.chain.generate_block()
    global_block["block_id"] = "final_merge_block"
    global_block["tx_count"] = len(global_block["transactions"])
    global_block["is_valid"] = True
    global_block["proposer"] = global_proposer
    global_consensus.confirm_block(global_block)
    end_time = time.perf_counter()

    merge_consensus_time = end_time - start_time
    print(f"‚è≥ ƒê·ªìng thu·∫≠n to√†n c·ª•c ƒë·∫°t ƒë∆∞·ª£c sau {merge_consensus_time:.4f} gi√¢y.")

    # === Save results to CSV ===
    csv_filename = "RQ1.2.csv"
    with open(csv_filename, mode="w", newline="") as f:
        writer = csv.writer(f)
        # Header (English)
        writer.writerow([
            "partition_id",
            "nodes_in_partition",
            "rounds_run",
            "accepted_blocks",
            "dropped_txs",
            "liveness_ratio",
            "fork_resolution_time",
            "merge_consensus_time"
        ])
        # Rows per partition
        for idx, partition in enumerate(partitions):
            writer.writerow([
                idx + 1,
                len(partition),
                rounds_per_partition[idx],
                accepted_blocks_per_partition[idx],
                dropped_txs_per_partition[idx],
                f"{liveness_per_partition[idx]*100:.2f}%",
                f"{fork_resolution_time:.2f}",
                f"{merge_consensus_time:.4f}"
            ])

    print(f"\nüíæ Results saved to {csv_filename}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Simulate partitioned blockchain with random-sized partitions and random rounds.")
    parser.add_argument("--nodes", type=int, default=100, help="S·ªë l∆∞·ª£ng node trong to√†n m·∫°ng")
    parser.add_argument("--partitions", type=int, default=2, help="S·ªë ph√¢n v√πng m·∫°ng kh√¥ng giao ti·∫øp")
    parser.add_argument("--tx-per-node", type=int, default=5, help="S·ªë l∆∞·ª£ng giao d·ªãch m·ªói node t·∫°o ra")
    parser.add_argument("--rounds", type=int, default=10, help="S·ªë v√≤ng ƒë·ªìng thu·∫≠n t·ªëi ƒëa cho m·ªói ph√¢n v√πng (th·ª±c t·∫ø s·∫Ω random 1..rounds)")
    args = parser.parse_args()

    simulate_partitioned_blockchain(
        num_nodes=args.nodes,
        num_partitions=args.partitions,
        tx_count_per_node=args.tx_per_node,
        max_rounds=args.rounds
    )
